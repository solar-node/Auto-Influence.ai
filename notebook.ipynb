{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ce349fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from dotenv import load_dotenv\n",
    "from typing import TypedDict, Annotated, List, Dict, Optional, Any\n",
    "from pydantic import BaseModel, Field\n",
    "import operator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "83bd3a66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3d9f4174",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatGoogleGenerativeAI(\n",
    "    model = 'gemini-2.5-flash'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "98d7baeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EvaluationSchema(BaseModel):\n",
    "\n",
    "    Feedback: str=Field(description=\"Detailed feedback for the content for linkedin\")\n",
    "    Score: str = Field(description = \"Score out of 10\", ge=0, le=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd7c3da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b08b57eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "structured_llm = model.with_structured_output(EvaluationSchema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bcb1499",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PostDraft(TypedDict):\n",
    "\n",
    "    \"\"\"A single object that holds all the data for one LinkedIN post\"\"\"\n",
    "    # Node 1 & 2\n",
    "    original_topic : Dict[str, Any] # Dict[str, Any]: gives you the flexibility to handle this real-world, messy data while still having some type safety (you know the keys are strings).\n",
    "    draft_text : str\n",
    "\n",
    "    # Node 3\n",
    "    fact_check: Optional[EvaluationSchema]\n",
    "    quality_check: Optional[EvaluationSchema]\n",
    "    engagement_check: Optional[EvaluationSchema]\n",
    "\n",
    "    # Node 4 : final evaluation\n",
    "    final_score : Optional[int]\n",
    "    final_feedback : Optional[str]\n",
    "\n",
    "    # Node 6 :Optimizer\n",
    "    revision_count : int\n",
    "\n",
    "class Published_post(TypedDict):\n",
    "\n",
    "    post_id : str\n",
    "    url : str\n",
    "    published_at : str\n",
    "    content_text : str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abf1bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoInfluenceState(TypedDict):\n",
    "\n",
    "    \"\"\"The main state for autonomus LinkedIn agent\"\"\"\n",
    "\n",
    "    # Node 8 (feedback) -> Node 1(Trend_analyzer)\n",
    "    learned_preferances : Optional[str]\n",
    "\n",
    "    # Node 1 -> Node 2(content generator)\n",
    "    trending_topics : List[Dict[str, Any]]\n",
    "\n",
    "    # This will contain LinkedIn drafts\n",
    "    current_drafts : List[PostDraft]\n",
    "\n",
    "    # Node 5(publisher) creates this \n",
    "    newly_published : List[Published_post]\n",
    "\n",
    "    # Node 7(memory) adds this to master log \n",
    "    master_log_published : Annotated[List[Published_post], operator.add]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f70d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def node_name(state: AutoInfluenceState):\n",
    "#     # read from state\n",
    "#     # do something (API call, LLM, computation)\n",
    "#     # return a partial dict of updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879c6d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trend_analyzer(state: AutoInfluenceState):\n",
    "\n",
    "    return \n",
    "\n",
    "def content_generator(state: AutoInfluenceState):\n",
    "    \n",
    "\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30079e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fact_checker(state: AutoInfluenceState):\n",
    "    \n",
    "    return\n",
    "\n",
    "def quality_checker(state: AutoInfluenceState):\n",
    "    \n",
    "    return\n",
    "\n",
    "def engagement_checker(state: AutoInfluenceState):\n",
    "    \n",
    "    return\n",
    "\n",
    "def final_evaluator(state: AutoInfluenceState):\n",
    "    \n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f87d436",
   "metadata": {},
   "outputs": [],
   "source": [
    "def route_evaluation(state: AutoInfluenceState):\n",
    "\n",
    "    drafts = state[\"current_drafts\"]\n",
    "\n",
    "    # If any draft passes the threshold -> Publish\n",
    "    if any(d[\"final_score\"] >= 8 for d in drafts) :\n",
    "        return \"publisher\"\n",
    "    \n",
    "    # If any draft hits max revisions -> restart content generation\n",
    "    elif any(d[\"revision_count\"] >=3 for d in drafts):\n",
    "        return \"content_generator\"\n",
    "    \n",
    "    # Otherwise -> keep optimizing\n",
    "    else:\n",
    "        return \"optimizer\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9810eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimizer(state: AutoInfluenceState):\n",
    "    \n",
    "    return\n",
    "\n",
    "def publisher(state: AutoInfluenceState):\n",
    "    \n",
    "    return\n",
    "\n",
    "def memory_logger(state: AutoInfluenceState):\n",
    "\n",
    "    return\n",
    "\n",
    "def feedback_updater(state: AutoInfluenceState):\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800ea192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now making the workflow\n",
    "graph = StateGraph(AutoInfluenceState)\n",
    "\n",
    "graph.add_node(\"trend_analyzer\", trend_analyzer)\n",
    "graph.add_node(\"content_generator\", content_generator)\n",
    "\n",
    "graph.add_edge(START, \"trend_analyzer\")\n",
    "graph.add_edge(\"trend_analyzer\", \"content_generator\")\n",
    "\n",
    "graph.add_node(\"fact_checker\", fact_checker)\n",
    "graph.add_node(\"engagement_checker\", engagement_checker)\n",
    "graph.add_node(\"quality_checker\", quality_checker)\n",
    "graph.add_node(\"final_evaluator\", final_evaluator) \n",
    "\n",
    "graph.add_edge(\"content_generator\", \"fact_checker\")\n",
    "graph.add_edge(\"content_generator\", \"enagaement_checker\")\n",
    "graph.add_edge(\"content_generator\", \"quality_checker\")\n",
    "\n",
    "graph.add_edge(\"fact_checker\", \"final_evaluator\")\n",
    "graph.add_edge(\"engagement_checker\", \"final_evaluator\")\n",
    "graph.add_edge(\"quality_checker\", \"final_evaluator\")\n",
    "\n",
    "graph.add_node(\"optimizer\", optimizer) \n",
    "graph.add_node(\"publisher\", publisher) \n",
    "graph.add_node(\"memory_logger\", memory_logger) \n",
    "graph.add_node(\"feedback_updater\", feedback_updater)\n",
    "\n",
    "graph.add_conditional_edges(\"final_evaluator\", route_evaluation)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
